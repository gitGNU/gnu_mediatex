The @mediatexO{} 
project intends to make easier as possible 
archives management by spreading and accessing @acronym{WORM} supports 
(as compact disks) and dedicated meta-data.
It is named @mediatexO{} 
because it aims to provide perennial
@acronym{URL} on electronic documents.

@cindex OAIS
@cindex NF Z 42-013
@mediatexO{} 
is inspired by @acronym{OAIS} archive system description
(@url{http://public.ccsds.org/@/publications/@/archive/@/650x0m2.pdf})
and aims to provide an @acronym{OAIS}'s archival storage entity. 
Its goal is to provide tools that help to manage a @acronym{NF Z 42-013} compliant supports collection.

@menu
* Who::		Who is it about?
* What::	What is happened?
* Where::	Where did it take place?
* When::	When did it take place?
* How::         How?
* How much::	How much?
* Why::         Why, why not?
@end menu

@node Who
@section Who

@image{mediatex-figures/who,,,,}
@cindex Publisher
@cindex User

The @mediatexO{} 
system interacts with 3 kind of users:
@itemize @bullet
@item 
@actorAdminO{} or @verb{!root!} system user configures and start services 
on a given host. He also creates or joins collections.
@item
@actorPublisherO{}s provide supports and meta-data for a collection: @procScriptsAddDelUser{}.
@item 
@actorUserO{} log-in via an internet browser to
browse collection and download archives: @procToolsApache{}.
@item 
@actor{Date} schedules the @mediatexO{} 
system's maintenance operations.
@end itemize

Association with system users is detailed next: @pxref{System users}.

@node What
@section What
@cindex Support 
@cindex ISO
@cindex Collection
@cindex Time-stamps
@cindex Claim-based authentication 

@mediatexO{} is mainly designed 
to provides an @sc{api} to manage supports (to drive jukeboxes).

As a distributed system, 
it allows several servers to share data and meta-data
related to collections of archives.

@mediatexO{} handle the @acronym{TCP} connections between remote servers.
It is designed to be installed directly on the archive producer's application servers.

@image{mediatex-figures/what,,,,}

@itemize @bullet
@item 
External supports, are spreads geographically over all servers.
Supports was first designed to be optical disks, 
but may also be a file you manually mount from what ever device 
and file systems, or any locally hosted files.
Because on GNU/Linux there is a bug with last block on @acronym{CD-ROM}, 
@mediatexO{} use the @acronym{ISO} format image to retrieve the support size. 
So, only the data disks are manage, not the audio ones for instance.

@itemize @bullet
@item
Information on support's images (what they contain and which servers provide them) is shared by all servers around the related collections.
@item 
A single support may be used on several hosts, 
for instance if we send it or if servers are located in the same place.
However, it is not recommended as @mediatexO{}
will badly deduce that the support is duplicated.
@item
A support may be share locally around several collections.
@end itemize

@item 
Servers are connected together via the internet public network and via
@acronym{NAT} gateway to reach hosts located on private networks.
@itemize @bullet
@item 
A server may participate to several collections.
@item
A server manages a local set of private supports including copies.
@item 
Each @mediatexO{} 
system instance is located on a given host. 
On a so call server, the 
@actorPublisher{} decides which support 
are shared by which collection. 
This association remains private and is not accessible remotely.
@end itemize

@item 
Collections groups archives contained on supports 
and make them available around the hosts that share the collection.
@itemize @bullet
@item 
A collection share support's contents using there related hashes and sizes
(deduced from the @acronym{ISO} image for @acronym{CDROM}).
Collection also share extraction rules and content's description 
using a catalogue index.
@item 
A collection should be shared by several servers, 
at less 2 to prevent from a site crash. 
All collection's access parameters are shared around all the hosts 
belonging to the collection.
@end itemize
@end itemize

Moreover, the collection concept is used to group document as 
@mediatexO{} 
does not handle dedicated life cycle on archives.

What it is not. @*
@cindex SGBD
@cindex Dynamic search
@cindex SEDA
@cindex XML
@cindex Time-stamps
@cindex Claim-based authentication
@cindex Single sign on

@mediatexO{} focus first on redundancy, done by software.
To do so:
@itemize @bullet
@item 
it isn't using @acronym{SGBD} to handle meta-data but text files.
@item 
it doesn't do mirroring replication (@acronym{rsync}), but share caches locally and access them remotely (read only).
@item 
is not a @acronym{PHP} application but build a static @acronym{WEB} site and provides a @acronym{CGI} application based on a @acronym{C} library. (@pxref{Portail})
@item 
is not based on a replicated @acronym{SGBD} but on a @acronym{GIT} repository.
@item 
it doesn't provide dynamic search. To do it you first have to export the meta-data into a database using the @acronym{C} library.
(@pxref{Linking})
@item 
it doesn't handle removal data from supports, which implies to re-burn CDs.
@item 
it isn't @acronym{SEDA} or any @acronym{XML} exchange protocol compliant 
(@url{http://www.archivesdefrance.culture.gouv.fr/seda/index.html}).
It can ever be interfaced with an upper layer server that will manage @acronym{XML} transactions and translations of meta-data. (@pxref{Linking})
@item
it doesn't manage time-stamps.
(@url{https://www.openssl.org/docs/manmaster/apps/ts.html}).
Time-stamps or whatever additional meta-data files may still be provided and stored as data files.
@item 
it doesn't manage claim-based authentication or any ``single sign on'' mechanism
(@url{https://en.wikipedia.org/wiki/OpenID}).
However, @acronym{APACHE2}'s @file{.htaccess} file directives
may still be added to the related meta-data file to do so (example provided as sub project).
@end itemize

Time-stamps and claim-based authentication servers which need a static certificate and a static domain name are monolithic servers and so, resides out of this scope. @mediatexO{} system is designed to be crashed anywhere but still alive elsewhere.

@node Where
@section Where
@cindex Git
@cindex Meta-data
@cindex Round-Robbin
@cindex DNS

@itemize @bullet
@item
Information about supports (support name, status, number of copies) 
is locally hold by each server keeping it private.
@item
Collection's meta-data files are duplicated on all servers,
but revisions are managed by a uniq @acronym{GIT} ``master'' server.

@image{mediatex-figures/where1,,,,}

@item
Archive's data files are stored in a cache for each collection by each server.
@item
A 
@actorUser{} query is distributed to all servers. 
If none of them can fulfil the query, the server receiving
the initial query asks for the @actor{User}'s mail address and registers it. 
The @actor{User} mail address is never sent to the other servers.

@image{mediatex-figures/where2,,,,}

@item
As the catalog provide static @acronym{HTML} content, a @acronym{DNS}'s round robbin is usable to switch between server's @acronym{WEB} interface in order to recover from a site crash.
@end itemize

@node When
@section When
@cindex Date

@itemize @bullet
@item
When 
@actorPublisher{} modifies the meta-data on a given server,
the other servers update there own copies later using the centralised 
@acronym{GIT} server.
@item 
When 
@actorUser{} queries for a file that no server provides in their own cache, 
the first requested server provides an @acronym{HTML} form 
in order to recall the 
@actor{User} latter, when the file becomes available.

@image{mediatex-figures/when,,,,}

@item
@actorDate{} is implement by the @procToolsCron{} daemon.
@item 
By reading the ``message of the day'', the 
@actorPublisherO{} 
is asked to do some maintenance operations such as:
@itemize @bullet
@item 
to provide external supports needed for extraction 
or needed to perform a periodic check.
@item
to backup files available from the cache on new supports 
and to share them with the related collection.
@end itemize
@end itemize

@node How
@section How
@cindex GNU
@cindex Syslog
@cindex Apache
@cindex Motd
@cindex Sendmail

@mediatexO{} system is built around other @acronym{GNU} 
@activityTools{}:
@itemize @bullet
@item 
Trace-ability is done by @sc{Syslog} for programs 
and by @sc{GIT} for changes in the meta-data.
@item 
Access is granted by @sc{Apache}, but when archives need to be retrieved, the 
@actorUser{} will be recall later using the default system mailer, that should
probably use the @sc{Sendmail} interface.
@item 
Catalogue index and extraction rules have to be provided or edited by hand by the @actorPublisher{} using a text editor.
@item 
Servers tasks are driven by @sc{Cron}. 
@item
@actor{Publisher} is asked to build and provide local supports 
via the host's @sc{Motd} (by default).
@item 
The support index and servers list files are internally managed by the 
@mediatex{} system.
@end itemize

Involved licences:
@itemize @bullet
@item Copy/past codes
@multitable @columnfractions .15 .15 .5
@headitem name @tab licence @tab website
@item getcgivar @tab MIT/NCSA? @tab from NCSA server exemples
@item e2fsck @tab GPLv2* @tab http://e2fsprogs.sourceforge.net/
@end multitable

(*) Author agree to re-license e2fsck's progress bar code under the LGPLv2

@sp 1
@item Compilation
@multitable @columnfractions .15 .15 .5
@headitem name @tab licence @tab website
@item automake @tab   GPLv2+ @tab  http://www.gnu.org/software/automake/
@item bison @tab      GPLv3+ @tab  http://www.gnu.org/software/bison/
@item gettext @tab    GPLv3+ @tab  http://www.gnu.org/software/gettext/
@item flex @tab       BSD @tab     http://flex.sourceforge.net/
@item help2man @tab   GPLv3+ @tab  http://www.gnu.org/software/help2man/
@item libavl @tab     LGPLv2+ @tab http://adtinfo.org/
@item libtool @tab    GPLv2+ @tab  http://www.gnu.org/software/libtool/
@item libssl-dev @tab BSD @tab     http://www.openssl.org/
@item make @tab       GPLv3+ @tab  http://www.gnu.org/software/make/
@item texinfo @tab    GPLv3+ @tab  http://www.gnu.org/software/texinfo/
@item transfig @tab   MIT @tab     http://www.xfig.org/ ?
@end multitable

@c @sp 1
@c @item Documentation
@c @multitable @columnfractions .15 .15 .5
@c @headitem name @tab licence @tab website
@c @item texinfo @tab    GPLv3+ @tab  http://www.gnu.org/software/texinfo/
@c @item transfig @tab   MIT @tab     http://www.xfig.org/ ?
@c @item ghostscript @tab AGPL-3+ @tab http://www.ghostscript.com
@c @end multitable

@sp 1
@item Documentation (others format than texinfo and man)
@multitable @columnfractions .15 .15 .5
@headitem name @tab licence @tab website
@item imagemagick @tab Apache2 @tab http://www.imagemagick.org/
@item texlive @tab     LPPL @tab    https://www.tug.org/texlive/
@end multitable

@sp 1
@item Installation
@multitable @columnfractions .15 .15 .5
@headitem name @tab licence @tab website
@item acl @tab             GPLv2+ @tab   http://savannah.nongnu.org/projects/acl/
@item apache2 @tab        Apache2 @tab   http://httpd.apache.org/
@item bc @tab              GPLv3+ @tab   http://www.gnu.org/software/bc/
@item bzip2 @tab           GPLv3? @tab   http://www.bzip.org/
@item cpio @tab            GPLv3+ @tab   http://www.gnu.org/software/cpio/
@item findutils @tab       GPLv3+ @tab   http://www.gnu.org/software/findutils/
@item git @tab             GPLv2+ @tab   https://git-scm.com/
@item gzip @tab            GPLv2+ @tab   http://www.gnu.org/software/gzip/
@item ssh @tab             BSD    @tab   http://www.openssh.com/
@item tar @tab             GPLv3+ @tab   http://www.gnu.org/software/tar/
@item unzip @tab           BSD    @tab   http://info-zip.org/
@item viewvc @tab          BSD    @tab   http://www.viewvc.org/
@end multitable
@c @item initramfs-tools @tab GPLv2+ @tab   https://wiki.debian.org/initramfs-tools

@sp 1
@item Optionnal: (and non-free)
@multitable @columnfractions .15 .15 .5
@headitem name @tab licence @tab website
@item rar @tab             EULA @tab     http://www.rarlab.com/
@item afio @tab               * @tab http://members.chello.nl/~k.holtman/afio.html
@end multitable

(*) not a standard OSI/FSF approved free software
@end itemize

@node How much
@section How much
@cindex Parsers
@cindex SGBD

In order to prevent from deny of services, 
we do not use a centralise database but text files spread on all servers
using @sc{GIT}. 

Consequently parsers needs a proportional amount of @acronym{CPU} and 
memory in regards to these file's sizes (whereas databases without indexe do not).
The generated @acronym{HTML} catalogue also requires much more place than
a dynamic web site does (moreover, limitation should comes from the number of available inodes on the partition where the @acronym{HTML} catalogue is 
stored).

All in all, the @mediatexO{} system is not designed to handle collections 
having more than half a million archives (whereas databases easily handle millions). It should handle several such ``not so big'' collections, but not toot much too.

Following tests are based on the @acronym{GIT} upgrade plus @acronym{HTML} catalogue generation, which is the more consumming query (and which imply parsing most meta-data files). It gives an idea of resources (size on disk, amount of memory and @acronym{CPU} time) involved.

@multitable @columnfractions .14 .14 .14 .14 .14 .14
@headitem archives @tab @acronym{GIT} @tab @acronym{RAM} @tab @acronym{HTML} @tab @acronym{HTML} inodes @tab time 
@item  27,550 @tab  30M @tab   74M @tab 357M @tab    88,717 @tab 1'06
@item  54,950 @tab  59M @tab  132M @tab 598M @tab   148,294 @tab 1'47
@item  82,398 @tab  88M @tab  191M @tab 840M @tab   207,985 @tab 3'25
@item 110,006 @tab 118M @tab  251M @tab 1,1G @tab   268,029 @tab 3'18
@item 137,561 @tab 147M @tab  310M @tab 1,3G @tab   328,002 @tab 5'21
@item 165,104 @tab 177M @tab  371M @tab 1,6G @tab   387,836 @tab 5'11
@item 192,771 @tab 207M @tab  432M @tab 1,8G @tab   447,971 @tab 5'47
@item 220,346 @tab 237M @tab  493M @tab 2,1G @tab   507,945 @tab 5'18
@item 247,861 @tab 267M @tab  553M @tab 2,3G @tab   567,664 @tab
@item 302,912 @tab 326M @tab  674M @tab 2,8G @tab   687,278 @tab 8'31
@item 330,371 @tab 356M @tab  735M @tab 3,0G @tab   746,934 @tab
@item 358,005 @tab 386M @tab  796M @tab 3,2G @tab   807,007 @tab 10'43
@item 385,425 @tab 416M @tab  856M @tab 3,5G @tab   866,551 @tab 11'17
@item 412,848 @tab 446M @tab  916M @tab 3,7G @tab   926,102 @tab 12'29
@item 440,405 @tab      @tab  977M @tab 3,9G @tab   985,990 @tab 
@item 467,899 @tab 505M @tab 1038M @tab 4,2G @tab 1,045,755 @tab 23'37
@item 495,383 @tab 535M @tab 1098M @tab 4,4G @tab 1,105,445 @tab 14'33
@end multitable

@note{}
@itemize @bullet
@item
This benchmark is run on a i686 operating system with an AMD Sempron(tm) Processor 3200+ and 2G of @acronym{RAM}. It make me aware that @acronym{ADM64} system use double of memory.
@item
Benchmark is done sequentially in order to test the @acronym{GIT} merging with a constant amount of data added each time.
Synchronisation times using @acronym{GIT} depends on the network connection,
and the upper benchmark is using the local network interface.
@item 
Time spent looks quiet linear (I was expecting @math{O(n*log(n)}). @acronym{GIT} push and @acronym{HTML} serialisation last most time, about 40% each. Parsing and serializing metadata last about 10% each.
@item
I was happily surprized that the logarithmic factor is not accented by the fact the files are serialised and parsed (into b-trees) using the same order.
@item
The audit report process is not optimised. It is possible to handle up to 1,000,000 archives or 500M of metadata by collection, but this particulary process has not been tested yet with more than 50,000 archives (as it last hours).
@end itemize

@node Why
@section Why
@cindex Round-Robbin
@cindex RPO
@cindex RTO
@cindex DRP
@cindex CAP theorem

Objective is to conserve, offer access and preserve intelligibility 
of electronic archives.
@itemize @bullet
@item 
Conception was made in order to provides redundancy, trace-ability 
and a shared @acronym{HTML} access.
@item 
@mediatexO{} make possible to rebuild the system mainly from its external 
supports (@note{} according that up to date catalogue and extraction meta-data are available on supports too).
This feature avoid too much entropy and ease migration/restitution.
@item 
It aims to provide a strong ``storage'' layer on which we should build a whole 
@acronym{OAIS} system. In that sense, it should provide a positive context 
for preservation operations, in prevision of time when the actual storage technologies will become outdated.
@item 
It tries to provide a dedicated workaround for the CAP theorem, 
using @acronym{GIT} merges.
(The also known as Brewer's theorem states that it is impossible 
for a distributed computer system to simultaneously provide all three 
of the following guarantees: Consistency, Availability and Partition 
tolerance.)
@item 
The just uploaded data are not safe: RPO (Recovery Point 
Objective) is roughly either 1 month (on supports) or 1 day (on caches).
But next, for managed data, the RTO (Recovery Time Objective) should be null:
DRP (Disaster Recovery Plan) simply consists on adding new servers to 
the collection (main configuration is already handle by the collection) 
and to include the new public @acronym{IP} addresses into the actual 
@acronym{DNS} round-Robbin's pool.
@end itemize

Why not use @mediatexO{}:
@itemize @bullet
@item
Not designed to handle millions of archives.
@item
Is a prototype and still need to be optimised.
@item 
Must not occult the forgetting right. 
As data are burned on optical disks, it is complicated to erase only a
part of them.
@end itemize

@c  LocalWords:  easely
